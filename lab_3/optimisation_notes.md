# Lab 3 : Optimisation PySpark - Rapport d'Analyse

**Date :** 10 novembre 2025  
**Projet :** Traitement distribu√© de donn√©es avec PySpark  
**Objectif :** Optimiser les performances par le partitionnement et assurer la tol√©rance aux pannes

---

## Objectifs du Lab

Ce lab vise √† :
1. **Tester plusieurs niveaux de partitionnement** (2, 4, 8 partitions)
2. **Observer et comparer les temps d'ex√©cution** pour identifier la configuration optimale
3. **Impl√©menter un checkpoint** pour assurer la tol√©rance aux pannes

---

## 1. Contexte et Donn√©es Utilis√©es

### Source des donn√©es
- **Fichier** : `logs_hourly.parquet` (g√©n√©r√© dans le Lab 2)
- **Contenu** : Logs web agr√©g√©s par heure et par utilisateur
- **Format** : Parquet (format optimis√© pour Spark)

---

## 2. Tests de Partitionnement

### 2.1 M√©thodologie

Pour chaque niveau de partitionnement test√© (2, 4, 8), nous avons :
1. **Repartitionn√©** le DataFrame avec `repartition(n)`
2. **Supprim√© le cache** avec `unpersist()` pour √©viter les biais
3. **Ex√©cut√© un count()** pour forcer le calcul
4. **Mesur√© le temps d'ex√©cution** avec le module `time`
(Voir fonction dans le fichier `lab_3/optimisation_notes.ipynb`)

### 2.2 R√©sultats des Tests

#### Test avec 2 partitions
```
============================================================
Test avec 2 partitions
============================================================
Nombre d'enregistrements       : 119,946
Nombre de partitions           : 2
Enregistrements par partition  : ~59,973
Temps d'ex√©cution              : 0.12 secondes
============================================================
```

---

#### Test avec 4 partitions
```
============================================================
Test avec 4 partitions
============================================================
Nombre d'enregistrements       : 119,946
Nombre de partitions           : 4
Enregistrements par partition  : ~29,986
Temps d'ex√©cution              : 0.15 secondes
============================================================
```

---

#### Test avec 8 partitions
```
============================================================
Test avec 8 partitions
============================================================
Nombre d'enregistrements       : 119,946
Nombre de partitions           : 8
Enregistrements par partition  : ~14,993
Temps d'ex√©cution              : 0.16 secondes
============================================================
```

---

### 2.3 Comparaison des Performances

```
============================================================
R√âSUM√â DES PERFORMANCES
============================================================
2 partitions : 0.12s
4 partitions : 0.15s
8 partitions : 0.16s
============================================================

Meilleure configuration : 2 partitions
============================================================
```

---

## üõ°Ô∏è 4. Checkpoint pour Tol√©rance aux Pannes

### 4.1 Pourquoi utiliser un checkpoint ?

Le checkpoint permet de :
- **Sauvegarder l'√©tat** du DataFrame sur le disque
- **R√©cup√©rer apr√®s une panne** sans tout recalculer
- **Couper les d√©pendances** du lineage (√©vite les RDD trop longs)

### 4.2 Impl√©mentation

#### Configuration du r√©pertoire de checkpoint
```python
checkpoint_dir = "./checkpoint"
os.makedirs(checkpoint_dir, exist_ok=True)
spark.sparkContext.setCheckpointDir(checkpoint_dir)
```

#### Application du checkpoint
```python
df_checkpointed = dataframe_8_partitions.checkpoint()
```

### 4.3 R√©sultats

```
R√©pertoire de checkpoint configur√© : ./checkpoint
Checkpoint appliqu√© sur le DataFrame
Nombre de partitions : 8
Nombre d'enregistrements : 119,946
```

---

## 5. Captures d'√©cran Spark UI

### 5.1 Vue des Jobs

**[![Spark UI - Jobs Tab](screenshots/spark_ui_jobs.png)]**

Cette capture montre :
- Les diff√©rents jobs ex√©cut√©s (un par test de partitionnement)
- Le temps d'ex√©cution de chaque job
- Le statut (Success/Failed)

---

### 5.2 Vue des Stages

**[![Spark UI - Stages Tab](screenshots/spark_ui_stages.png)]**

Cette capture illustre :
- Les stages de chaque job
- Le nombre de t√¢ches par stage
- La distribution du temps d'ex√©cution

---

### 5.3 DAG Visualization

**[![Spark UI - DAG Visualization](screenshots/spark_ui_dag.png)]**

Le graphe DAG (Directed Acyclic Graph) montre :
- Le flux d'ex√©cution des transformations
- Les √©tapes de shuffle (exchange)
- Les op√©rations de repartitionnement

---

**Fin du rapport**
